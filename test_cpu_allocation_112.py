#!/usr/bin/env python3
"""
Test script to verify CPU allocation with 112 CPUs per task
"""

import os
import sys

def test_single_task_allocation():
    """Test CPU allocation for single task (112 CPUs, 384 workers)"""
    print("=" * 80)
    print("æµ‹è¯• 1: å•ä»»åŠ¡ CPU åˆ†é… (112 CPUs, 384 workers)")
    print("=" * 80)

    total_cpus = 112
    num_workers = 384
    batch_size = 64
    sample_num = 6

    # Auto-calculation formula
    cpu_per_worker = (total_cpus * 0.9) / num_workers
    cpu_per_worker = max(0.1, min(2.0, cpu_per_worker))

    total_cpu_used = cpu_per_worker * num_workers
    utilization = (total_cpu_used / total_cpus) * 100
    theoretical_concurrent = batch_size * sample_num

    print(f"\né…ç½®å‚æ•°:")
    print(f"  Total CPUs: {total_cpus}")
    print(f"  Workers: {num_workers}")
    print(f"  Batch size: {batch_size}")
    print(f"  Sample num: {sample_num}")
    print(f"  Theoretical concurrent tasks: {theoretical_concurrent}")

    print(f"\nCPU åˆ†é…:")
    print(f"  CPU per worker: {cpu_per_worker:.4f}")
    print(f"  Total CPU used: {total_cpu_used:.2f}")
    print(f"  CPU utilization: {utilization:.1f}%")

    print(f"\néªŒè¯:")
    all_workers_can_start = num_workers <= int(total_cpus / 0.1)  # Minimum 0.1 CPU per worker
    print(f"  âœ… æ‰€æœ‰ {num_workers} ä¸ª worker éƒ½èƒ½è¢«åˆ›å»º" if all_workers_can_start else f"  âŒ æ— æ³•åˆ›å»ºæ‰€æœ‰ worker")
    print(f"  âœ… CPU åˆ©ç”¨ç‡è¾¾åˆ° {utilization:.1f}%" if utilization >= 85 else f"  âš ï¸  CPU åˆ©ç”¨ç‡è¾ƒä½: {utilization:.1f}%")
    print(f"  âœ… è¶³å¤Ÿæ”¯æŒ {theoretical_concurrent} ä¸ªå¹¶å‘ä»»åŠ¡" if num_workers >= theoretical_concurrent else f"  âš ï¸  Worker æ•°é‡ä¸è¶³")

    return all_workers_can_start and utilization >= 85


def test_concurrent_tasks_allocation():
    """Test CPU allocation for two concurrent tasks (224 CPUs, 768 workers)"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: ä¸¤ä»»åŠ¡å¹¶è¡Œ CPU åˆ†é… (224 CPUs, 768 workers)")
    print("=" * 80)

    total_cpus = 224
    num_workers_per_task = 384
    num_tasks = 2
    total_workers = num_workers_per_task * num_tasks

    # Auto-calculation formula
    cpu_per_worker = (total_cpus * 0.9) / total_workers
    cpu_per_worker = max(0.1, min(2.0, cpu_per_worker))

    total_cpu_used = cpu_per_worker * total_workers
    utilization = (total_cpu_used / total_cpus) * 100

    print(f"\né…ç½®å‚æ•°:")
    print(f"  Total CPUs: {total_cpus}")
    print(f"  Tasks: {num_tasks}")
    print(f"  Workers per task: {num_workers_per_task}")
    print(f"  Total workers: {total_workers}")

    print(f"\nCPU åˆ†é…:")
    print(f"  CPU per worker: {cpu_per_worker:.4f}")
    print(f"  Total CPU used: {total_cpu_used:.2f}")
    print(f"  CPU utilization: {utilization:.1f}%")

    print(f"\néªŒè¯:")
    all_workers_can_start = total_workers <= int(total_cpus / 0.1)
    print(f"  âœ… æ‰€æœ‰ {total_workers} ä¸ª worker éƒ½èƒ½è¢«åˆ›å»º" if all_workers_can_start else f"  âŒ æ— æ³•åˆ›å»ºæ‰€æœ‰ worker")
    print(f"  âœ… CPU åˆ©ç”¨ç‡è¾¾åˆ° {utilization:.1f}%" if utilization >= 85 else f"  âš ï¸  CPU åˆ©ç”¨ç‡è¾ƒä½: {utilization:.1f}%")

    return all_workers_can_start and utilization >= 85


def test_gpu_group_isolation():
    """Test GPU group isolation paths"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: GPU ç»„éš”ç¦»è·¯å¾„")
    print("=" * 80)

    scenarios = [
        {
            "name": "Task 1 (GPU 0,1)",
            "cuda_visible": "0,1",
            "gpu_group": "gpu_0_1",
            "experiment": "pychecker_rl_after_stl_8B_gpu01",
        },
        {
            "name": "Task 2 (GPU 3,4)",
            "cuda_visible": "3,4",
            "gpu_group": "gpu_3_4",
            "experiment": "pychecker_rl_after_stl_8B_gpu34",
        },
    ]

    num_workers = 384

    for scenario in scenarios:
        print(f"\nğŸ“Š {scenario['name']}")
        print(f"   CUDA_VISIBLE_DEVICES: {scenario['cuda_visible']}")
        print(f"   GPU Group: {scenario['gpu_group']}")
        print(f"   Experiment: {scenario['experiment']}")
        print(f"   Workers: {num_workers}")
        print(f"   ç¤ºä¾‹è·¯å¾„:")

        for rollout_idx in [0, 1, 383]:
            worker_id = rollout_idx % num_workers
            path = f"tmp/pychecker_tasks/{scenario['gpu_group']}/worker_{worker_id}/env_0/rollout_{rollout_idx}/turn_0"
            print(f"     rollout_{rollout_idx:3d} â†’ {path}")

    print(f"\nâœ… å…³é”®ç‰¹ç‚¹:")
    print(f"   - ä¸åŒ GPU ç»„æœ‰å®Œå…¨ç‹¬ç«‹çš„ç›®å½•æ ‘")
    print(f"   - åŒä¸€ worker ID åœ¨ä¸åŒ GPU ç»„ä¸‹è·¯å¾„ä¸åŒ")
    print(f"   - æ— æ–‡ä»¶å†²çªï¼Œå¯ä»¥å®‰å…¨å¹¶è¡Œè¿è¡Œ")

    return True


def test_script_configurations():
    """Test script configurations"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 4: è„šæœ¬é…ç½®éªŒè¯")
    print("=" * 80)

    scripts = [
        {
            "name": "pychecker_rl_L2_multi_agent.sh",
            "gpu": "0,1",
            "cpus": 112,
            "workers": 384,
            "experiment": "pychecker_rl_after_stl_8B_gpu01",
        },
        {
            "name": "pychecker_rl_L2_multi_agent_1.sh",
            "gpu": "3,4",
            "cpus": 112,
            "workers": 384,
            "experiment": "pychecker_rl_after_stl_8B_gpu34",
        },
    ]

    print(f"\n{'è„šæœ¬':<40} {'GPU':<10} {'CPUs':<8} {'Workers':<10} {'å®éªŒåç§°':<40}")
    print("-" * 120)

    for script in scripts:
        print(f"{script['name']:<40} {script['gpu']:<10} {script['cpus']:<8} {script['workers']:<10} {script['experiment']:<40}")

    print(f"\nâœ… ä¸¤ä¸ªè„šæœ¬é…ç½®ä¸€è‡´ï¼Œåªæœ‰ GPU å’Œå®éªŒåç§°ä¸åŒ")
    print(f"âœ… å¯ä»¥åŒæ—¶è¿è¡Œè€Œä¸ä¼šæœ‰èµ„æºå†²çª")

    return True


def test_comparison_with_old_config():
    """Compare with old configuration"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 5: æ–°æ—§é…ç½®å¯¹æ¯”")
    print("=" * 80)

    configs = [
        {
            "name": "æ—§é…ç½® (å•ä»»åŠ¡)",
            "cpus": 224,
            "workers": 500,
            "cpu_per_worker": (224 * 0.9) / 500,
        },
        {
            "name": "æ–°é…ç½® (å•ä»»åŠ¡)",
            "cpus": 112,
            "workers": 384,
            "cpu_per_worker": (112 * 0.9) / 384,
        },
        {
            "name": "æ–°é…ç½® (ä¸¤ä»»åŠ¡å¹¶è¡Œ)",
            "cpus": 224,
            "workers": 768,
            "cpu_per_worker": (224 * 0.9) / 768,
        },
    ]

    print(f"\n{'é…ç½®':<25} {'CPUs':<8} {'Workers':<10} {'CPU/Worker':<15} {'CPUåˆ©ç”¨ç‡':<12}")
    print("-" * 80)

    for config in configs:
        cpus = config["cpus"]
        workers = config["workers"]
        cpu_per_worker = max(0.1, min(2.0, config["cpu_per_worker"]))
        utilization = (cpu_per_worker * workers) / cpus * 100

        print(f"{config['name']:<25} {cpus:<8} {workers:<10} {cpu_per_worker:<15.4f} {utilization:<12.1f}%")

    print(f"\nğŸ’¡ å…³é”®æ”¹è¿›:")
    print(f"   âœ… æ”¯æŒä¸¤ä»»åŠ¡å¹¶è¡Œè¿è¡Œ (å„ 112 CPUs)")
    print(f"   âœ… Worker æ•°é‡ä¼˜åŒ–åˆ° 384 (åŒ¹é… batch_size Ã— sample_num)")
    print(f"   âœ… CPU åˆ©ç”¨ç‡ä¿æŒ 90%")
    print(f"   âœ… GPU ç»„å®Œå…¨éš”ç¦»")

    return True


def main():
    """Run all tests"""
    print("\n" + "ğŸ§ª " * 40)
    print("CPU åˆ†é…å’Œè„šæœ¬é…ç½®æµ‹è¯• (112 CPUs per task, 384 workers)")
    print("ğŸ§ª " * 40 + "\n")

    tests = [
        ("å•ä»»åŠ¡ CPU åˆ†é…", test_single_task_allocation),
        ("ä¸¤ä»»åŠ¡å¹¶è¡Œ CPU åˆ†é…", test_concurrent_tasks_allocation),
        ("GPU ç»„éš”ç¦»è·¯å¾„", test_gpu_group_isolation),
        ("è„šæœ¬é…ç½®éªŒè¯", test_script_configurations),
        ("æ–°æ—§é…ç½®å¯¹æ¯”", test_comparison_with_old_config),
    ]

    passed = 0
    failed = 0

    for test_name, test_func in tests:
        try:
            result = test_func()
            if result:
                passed += 1
                print(f"\nâœ… {test_name}: PASSED")
            else:
                failed += 1
                print(f"\nâŒ {test_name}: FAILED")
        except Exception as e:
            failed += 1
            print(f"\nâŒ {test_name}: ERROR - {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 80)
    print(f"æµ‹è¯•æ€»ç»“: {passed} é€šè¿‡, {failed} å¤±è´¥")
    print("=" * 80)

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é…ç½®å·²ä¼˜åŒ–å®Œæˆã€‚")
        print("\nğŸ“š ä½¿ç”¨æ–¹æ³•:")
        print("\n  å•ä»»åŠ¡è¿è¡Œ:")
        print("    cd scripts/train/pychecker_rl")
        print("    bash pychecker_rl_L2_multi_agent.sh")
        print("\n  ä¸¤ä»»åŠ¡å¹¶è¡Œè¿è¡Œ:")
        print("    Terminal 1: bash pychecker_rl_L2_multi_agent.sh")
        print("    Terminal 2: bash pychecker_rl_L2_multi_agent_1.sh")
        print("\nğŸ“Š å…³é”®é…ç½®:")
        print("    - æ¯ä¸ªä»»åŠ¡: 112 CPUs, 384 workers, 2 GPUs")
        print("    - CPU per worker: 0.2625")
        print("    - CPU utilization: 90%")
        print("    - GPU ç»„å®Œå…¨éš”ç¦»")
        return 0
    else:
        print(f"\nâš ï¸  {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
